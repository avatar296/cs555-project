services:
  kafka:
    # https://hub.docker.com/r/apache/kafka
    image: apache/kafka:4.1.0
    container_name: kafka
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_LISTENERS=INTERNAL://:9092,EXTERNAL://:29092,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_NUM_PARTITIONS=12
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "29092:29092"

  kafka-ui:
    # https://github.com/provectus/kafka-ui
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    ports:
      - 8080:8080

  # Spark Master
  spark-master:
    build: ./spark
    image: cs555-project-spark:3.5.0
    container_name: spark-master
    command: bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_NO_DAEMONIZE=true
    ports:
      - "8081:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master Port
    volumes:
      - spark-logs:/opt/spark/logs
      - spark-state:/tmp/state-store

  # Spark Worker
  spark-worker:
    build: ./spark
    image: project-spark:3.5.0
    container_name: spark-worker
    command: bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
    depends_on:
      - spark-master
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_NO_DAEMONIZE=true
    volumes:
      - spark-logs:/opt/spark/logs
      - spark-state:/tmp/state-store

volumes:
  spark-logs:
  spark-state:
